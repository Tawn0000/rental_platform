{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取有效信息，将爬回的HTML页面 -> 房源数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import settings\n",
    "import stations_information\n",
    "import hashlib\n",
    "import logging\n",
    "import requests\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "import multiprocessing\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def _hash(data):\n",
    "    md5 = hashlib.md5() # 应用MD5算法\n",
    "    md5.update(data.encode('utf-8'))\n",
    "    return md5.hexdigest()\n",
    "\n",
    "from fontTools.ttLib import TTFont\n",
    "import base64\n",
    "import re\n",
    "import io\n",
    "\n",
    "\n",
    "def getKey(script):\n",
    "    try:\n",
    "        return re.findall(r\"base64,(.*)'\\).format\", script)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def getFont(key):\n",
    "    data = base64.b64decode(key)\n",
    "    fonts = TTFont(io.BytesIO(data))\n",
    "    return fonts.getBestCmap()\n",
    "\n",
    "\n",
    "def getDigit(str):\n",
    "    d = re.findall(r'(\\d+)', str)[0]\n",
    "    return int(d) - 1\n",
    "\n",
    "\n",
    "def getRealValue(script, string):\n",
    "    key = getKey(script)\n",
    "#     print(key)\n",
    "    fontMap = getFont(key)\n",
    "    newMap = dict()\n",
    "    #微软雅黑的对应的编码\n",
    "    font58 = {\n",
    "        '閏': '0x958f',\n",
    "        '鸺': '0x9e3a',\n",
    "        '麣': '0x9ea3',\n",
    "        '餼': '0x993c',\n",
    "        '鑶': '0x9476',\n",
    "        '龤': '0x9fa4',\n",
    "        '齤': '0x9f64',\n",
    "        '龥': '0x9fa5',\n",
    "        '龒': '0x9f92',\n",
    "        '驋': '0x9a4b',\n",
    "    }\n",
    "    for key in fontMap.keys():\n",
    "        value = getDigit(fontMap[key])\n",
    "        key = hex(key)\n",
    "        newMap[key] = value\n",
    "    result = ''\n",
    "    for char in string:\n",
    "        temp = font58[char]\n",
    "        value = newMap[temp]\n",
    "        result = '%s%d' % (result, value)\n",
    "    return result\n",
    "\n",
    "def decode(script, price_str):\n",
    "    try:\n",
    "        res = '.'.join([getRealValue(script, it) for it in price_str.split('.')])\n",
    "    except Exception as e:\n",
    "        res = price_str\n",
    "#         print(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_coordinate(keywords, city='上海'):\n",
    "    url = 'https://restapi.amap.com/v3/assistant/inputtips?output=json&city=%s&keywords=%s&key=%s'\n",
    "    url = url % (city, keywords, settings.key)\n",
    "#     print(url)\n",
    "    response = requests.get(url)\n",
    "    answer = response.json()\n",
    "#     print(answer)\n",
    "    if answer.get('status') == '1' and answer.get('count') != '0':\n",
    "#         print(answer.get('tips')[0].get('name'))\n",
    "        res = answer.get('tips')[0].get('location')\n",
    "        return res if res else None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def get_distance(origin_list, destination):\n",
    "#     print(destination)\n",
    "    if not origin_list or not destination:\n",
    "        return [1000000000 for i in range(len(origin_list))]\n",
    "    url = 'https://restapi.amap.com/v3/distance?origins=%s&destination=%s&output=json&key=%s'\n",
    "    origin_str = '|'.join(origin_list)\n",
    "    url = url % (origin_str, destination, settings.key)\n",
    "    response = requests.get(url)\n",
    "    answer = response.json()\n",
    "#     print(url)\n",
    "#     print(answer)\n",
    "    if answer.get('status') == '1':\n",
    "        return [int(item['distance']) if item else 1000000000 for item in answer.get('results')]\n",
    "    else:\n",
    "        return [1000000000 for i in range(len(origin_list))]\n",
    "\n",
    "\n",
    "def get_traffic(coordinate):\n",
    "    station_coordinate = stations_information.station_coordinate\n",
    "#     coordinate = '116.310905,39.992806'\n",
    "    station_list = [station for station in station_coordinate.keys()]\n",
    "    # len(station_list)\n",
    "    station_coordinate_list = []\n",
    "    distance_list = []\n",
    "    for (i, station) in enumerate(station_list):\n",
    "        station_coordinate_list.append(station_coordinate[station])\n",
    "        if (i+1) % 100 == 0 or i+1 == len(station_list):\n",
    "            distance_list += get_distance(station_coordinate_list, coordinate)\n",
    "#             print(len(station_coordinate_list))\n",
    "            station_coordinate_list = []\n",
    "\n",
    "    if distance_list.count(None) == len(distance_list):\n",
    "        return None\n",
    "    else:\n",
    "        min_distance = min(distance_list)\n",
    "        min_index = distance_list.index(min_distance)\n",
    "        min_station = station_list[min_index]\n",
    "\n",
    "        if min_station != None and min_distance <= 2000:\n",
    "            res = '距' + stations_information.station_subway[min_station] + min_station + '地铁站' + str(min_distance) + '米'\n",
    "        else:\n",
    "            res = None\n",
    "        return res\n",
    "\n",
    "        print(station_list)\n",
    "        print(distance_list)\n",
    "        print(min_distance)\n",
    "        print(min_index)\n",
    "        print(min_station)\n",
    "        print(res)\n",
    "\n",
    "# coordinate = '121.192279,31.171247'\n",
    "# get_traffic(coordinate)\n",
    "    \n",
    "\n",
    "def worker_1(st, num):\n",
    "#     print(\"*\")\n",
    "    # 注意父子进程不能共用同一MongoDB connection\n",
    "    MONGO_COLLECTION_1 = 'fang_details_crawl'\n",
    "    MONGO_COLLECTION_OUTPUT = 'house_new'\n",
    "    client = MongoClient(settings.MONGO_URI)\n",
    "    database = client['test']\n",
    "    collection_1 = database[MONGO_COLLECTION_1]\n",
    "    collection_out = database[MONGO_COLLECTION_OUTPUT]\n",
    "    \n",
    "    # 建立索引\n",
    "    v = {\n",
    "        'raw_key': {'name': 'raw_key', 'unique': True},\n",
    "        'url': {'name': 'url'},\n",
    "        'domain': {'name': 'domain'},\n",
    "        'price': {'name':'price'},\n",
    "        'size': {'name':'size'}\n",
    "        }\n",
    "    for key, kwargs in v.items():\n",
    "        collection_out.create_index(key, background=True, **kwargs)\n",
    "\n",
    "    # 清洗 sh.zu.fang.com\n",
    "    items = []\n",
    "    cur = collection_1.find().skip(st).limit(num)\n",
    "    cnt = 0\n",
    "    requests = []\n",
    "    for item in cur:\n",
    "#         print(cnt)\n",
    "#         cnt += 1\n",
    "#         print(item['html'])\n",
    "#         print(item['raw_key'])\n",
    "#         print(item['url'])\n",
    "        soup = BeautifulSoup(item['html'], features=\"lxml\")\n",
    "        price_tag = soup.find(name='div', attrs={\"class\":\"trl-item sty1\"})\n",
    "        if not price_tag:\n",
    "            price_tag = soup.find(name='div', attrs={\"class\":\"trl-item sty1 rel\"})\n",
    "        price = price_tag.i.string\n",
    "        pay_way = re.search(pattern = '（.*?）', string=price_tag.text, flags=0).group().strip('（）')\n",
    "        tag = [it.string for it in soup.find(name='div', attrs={'class':\"bqian clearfix\"}).find_all('span')] if soup.find(name='div', attrs={'class':\"bqian clearfix\"}) else []\n",
    "        basic_info = [it.string for it in soup.find_all(name='div', attrs={'class':\"tt\"})]\n",
    "        try:\n",
    "            intro = soup.find(name='div', attrs={'class':\"cont yc\"}).text.strip().replace(\"\\n\\n\",\"\").replace(' ','')\n",
    "        except Exception as e:\n",
    "            intro = None\n",
    "            \n",
    "        try:\n",
    "            facility = [it.string for it in soup.find(name='div', attrs={'class':\"cont clearfix\"}).find_all('li')]\n",
    "        except Exception as e:\n",
    "            facility = None\n",
    "            \n",
    "        try:\n",
    "            community = soup.find(name='div', attrs={'class':\"rcont\"}).find(name='a', attrs={'id':'agantzfxq_C02_07'}).string\n",
    "        except Exception as e:\n",
    "            community =  soup.find(name='div', attrs={'class':\"rcont\"}).text\n",
    "            \n",
    "        address_info = [it.text.strip() for it in soup.find_all(name='div', attrs={'class':\"rcont\"})]\n",
    "        if len(address_info) == 3:\n",
    "            traffic = address_info[1]\n",
    "            detail = address_info[2]\n",
    "        else:\n",
    "            traffic = None\n",
    "            detail = address_info[1]\n",
    "        try:\n",
    "            pic = ['https:' + it.get('src') for it in soup.find(name='div', attrs={'class':\"cont-sty1 clearfix\"}).find_all(name='img', attrs={'alt':\"房源图片\"})]\n",
    "        except Exception as e:\n",
    "            pic = None\n",
    "            \n",
    "        # 补充address和traffic\n",
    "        address = community + detail\n",
    "        coordinate = get_coordinate(address, '上海')\n",
    "        if not traffic or traffic.find('米')==-1:\n",
    "            traffic = get_traffic(coordinate)\n",
    "        \n",
    "        item_out = {\n",
    "            'raw_key': _hash(item['raw_key']),\n",
    "            'price': price,    # 单位元每月\n",
    "            'pay_way': pay_way, # 付款方式，如押一付三等\n",
    "            'tag': tag,     # 房屋标签\n",
    "            'rent_way': basic_info[0],  # 出租方式\n",
    "            'house_type': basic_info[1], # 户型\n",
    "            'size': basic_info[2],    # 面积\n",
    "            'orientation': basic_info[3], # 朝向\n",
    "            'floor':  basic_info[4], # 楼层\n",
    "            'decorate_type': basic_info[5], # 装修类型\n",
    "            'intro': intro,   # 房屋介绍\n",
    "            'facility': facility, # 设施\n",
    "            'traffic': traffic,\n",
    "            'address': {\"city\": \"上海\", \"district\": item['district'], \"community\": community, \"detail\": detail, 'coordinate':coordinate},\n",
    "            'pic': pic, # 房源图片\n",
    "            'domain': item['domain'], #来源网站\n",
    "            'url': item['raw_key'], #来源网址\n",
    "        }\n",
    "        requests.append(UpdateOne({'raw_key': item_out['raw_key']}, {'$set': dict(item_out)}, upsert=True))\n",
    "#         for (k,v) in item_out.items():\n",
    "#             print(k,':',v)\n",
    "#     批处理\n",
    "    collection_out.bulk_write(requests)\n",
    "#     print(result.upserted_ids)\n",
    "    print(\"[%s-%s) is ok\" % (st, st+num))\n",
    "    print(get_coordinate('无锡江南大学'))\n",
    "    coordinate = '121.192279,31.161247'\n",
    "    print(get_traffic(coordinate))\n",
    "\n",
    "\n",
    "def worker_2(st, num):\n",
    "    MONGO_COLLECTION_2 = 'zufang58_details_crawl'\n",
    "    MONGO_COLLECTION_OUTPUT = 'house_new'\n",
    "    client = MongoClient(settings.MONGO_URI)\n",
    "    database = client['test']\n",
    "    collection_2 = database[MONGO_COLLECTION_2]\n",
    "    collection_out = database[MONGO_COLLECTION_OUTPUT]\n",
    "    # 建立索引\n",
    "    v = {\n",
    "        'raw_key': {'name': 'raw_key', 'unique': True},\n",
    "        'url': {'name': 'url'},\n",
    "        'domain': {'name': 'domain'},\n",
    "        'price': {'name':'price'},\n",
    "        'size': {'name':'size'}\n",
    "        }\n",
    "    for key, kwargs in v.items():\n",
    "        collection_out.create_index(key, background=True, **kwargs)\n",
    "    items = []\n",
    "    requests = []\n",
    "    cur = collection_2.find().skip(st).limit(num)\n",
    "    err_list = []\n",
    "    cnt = st\n",
    "    for item in cur:\n",
    "#         cnt +=1\n",
    "#         print(cnt)\n",
    "#         print(item['raw_key'])\n",
    "#         print(item['url'])\n",
    "#         print(item['html'])\n",
    "        soup = BeautifulSoup(item['html'], features=\"lxml\")\n",
    "        try:\n",
    "            price_str = soup.find(name='b', attrs={'class':'f36 strongbox'}).string.strip()\n",
    "        except Exception as e:\n",
    "            err_list.append(item['url'])\n",
    "            continue\n",
    "        script = soup.find('head').find_all('script')[0].text  \n",
    "#         try:\n",
    "        price = decode(script, price_str) # 价格解密\n",
    "#         except Exception as e:\n",
    "#             price = price_str\n",
    "#             print(price)\n",
    "        pay_way = soup.find(name='span', attrs={\"class\":\"instructions\"}).text\n",
    "        tag = [it.text for it in soup.find(name='ul', attrs={\"class\":\"introduce-item\"}).find_all(\"em\")]\n",
    "        basic_info = [it.text for it in soup.find(name='ul', attrs={\"class\":\"f14\"}).find_all(\"span\")]\n",
    "        house_type =  basic_info[3].strip().replace(' ','')\n",
    "        house_type_list = house_type.split(b'\\xc2\\xa0'.decode())\n",
    "                \n",
    "        tmp_list = []\n",
    "        tmp_list.append(decode(script, house_type_list[0][0]) + '室')\n",
    "        tmp_list.append(decode(script, house_type_list[0][2]) + '厅')\n",
    "        tmp_list.append(decode(script, house_type_list[0][4]) + '卫')\n",
    "        size = decode(script, house_type_list[2][:-1])\n",
    "        house_type = ' '.join(tmp_list)\n",
    "            \n",
    "        try:\n",
    "            decorate_type = house_type_list[4]\n",
    "        except Exception as e:\n",
    "            decorate_type = None\n",
    "            \n",
    "        tmp_list = basic_info[5].split(b'\\xc2\\xa0'.decode())\n",
    "        orientation = tmp_list[0]\n",
    "        floor_list = []\n",
    "#         print(tmp_list)\n",
    "        if tmp_list[2] == '':\n",
    "            floor = None\n",
    "        else:\n",
    "            for it in tmp_list[2].split(' / '):\n",
    "                if it[0] in ['中','高','低']:\n",
    "                    floor_list.append(it)\n",
    "                elif it[0] == '共':\n",
    "                    floor_list.append(it[0] + decode(script, it[1:-1]) + it[-1])\n",
    "                else:\n",
    "                    floor_list.append(decode(script, it[:-1]) + it[-1])\n",
    "            floor = ' '.join(floor_list)\n",
    "            \n",
    "        try:\n",
    "            intro = soup.find(name='ul', attrs={\"class\":\"introduce-item\"}).find_all(name='span', attrs={\"class\":\"a2\"})[1].text\n",
    "        except Exception as e:\n",
    "            intro = soup.find(name='ul', attrs={\"class\":\"introduce-item\"}).find_all(name='span', attrs={\"class\":\"a2\"})[0].text\n",
    "            \n",
    "        try:\n",
    "            facility = [it.text for it in soup.find(name='ul', attrs={\"class\":\"house-disposal\"}).find_all('li')]\n",
    "        except Exception as e:\n",
    "            facility = None\n",
    "            \n",
    "        try:\n",
    "            traffic = soup.find(name='em', attrs={'class':\"dt c_888 f12\"}).string\n",
    "        except Exception as e:\n",
    "            traffic = None\n",
    "          \n",
    "        try:\n",
    "            pic = [it.get('lazy_src') for it in soup.find(name='ul', attrs={'class':\"house-pic-list\"}).find_all('img')]\n",
    "        except Exception as e:\n",
    "            pic = None\n",
    "        \n",
    "        detail = basic_info[11].strip()\n",
    "        community = basic_info[7].strip()\n",
    "        \n",
    "        # 补充address和traffic\n",
    "        address = community + detail\n",
    "        coordinate = get_coordinate(address, '上海')\n",
    "        if not traffic or traffic.find('米')==-1:\n",
    "            traffic = get_traffic(coordinate)\n",
    "        \n",
    "        item_out = {\n",
    "        'raw_key': _hash(item['raw_key']),\n",
    "        'price': price,    # 单位元每月\n",
    "        'pay_way': pay_way, # 付款方式，如押一付三等\n",
    "        'tag': tag,     # 房屋标签\n",
    "        'rent_way': basic_info[1],  # 出租方式\n",
    "        'house_type': house_type, # 户型\n",
    "        'size': size,    # 面积\n",
    "        'orientation': orientation, # 朝向\n",
    "        'floor':  floor, # 楼层\n",
    "        'decorate_type': decorate_type, # 装修类型\n",
    "        'intro': intro,   # 房屋介绍\n",
    "        'facility': facility, # 设施\n",
    "        'traffic': traffic,\n",
    "        'address': {\"city\": \"上海\", \"district\": item['district'], \"community\": community, \"detail\": detail, 'coordinate': coordinate},\n",
    "        'pic': pic, # 房源图片\n",
    "        'domain': item['domain'], #来源网站\n",
    "        'url': item['raw_key'], #来源网址\n",
    "    }\n",
    "#         for (k,v) in item_out.items():\n",
    "#             print(k,':',v)\n",
    "        requests.append(UpdateOne({'raw_key': item_out['raw_key']}, {'$set': dict(item_out)}, upsert=True))\n",
    "    # 批处理\n",
    "    collection_out.bulk_write(requests)\n",
    "#     print(result.upserted_ids)\n",
    "    print('len(err_list): ', len(err_list))\n",
    "#     for url in err_list:\n",
    "#         print(url)\n",
    "    print(\"[%s-%s) is ok\" % (st, st+num))\n",
    "    print(get_coordinate('无锡江南大学'))\n",
    "    coordinate = '121.192279,31.161247'\n",
    "    print(get_traffic(coordinate))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(err_list):  142\n",
      "[30000-31525) is ok\n",
      "120.27116,31.483652\n",
      "距上海地铁17号线赵巷地铁站1米\n",
      "len(err_list):  225\n",
      "[36100-37625) is ok\n",
      "120.27116,31.483652\n",
      "距上海地铁17号线赵巷地铁站1米\n",
      "len(err_list):  147\n",
      "[34575-36100) is ok\n",
      "120.27116,31.483652\n",
      "距上海地铁17号线赵巷地铁站1米\n",
      "len(err_list):  120\n",
      "[31525-33050) is ok\n",
      "120.27116,31.483652\n",
      "距上海地铁17号线赵巷地铁站1米\n",
      "len(err_list):  159\n",
      "[33050-34575) is ok\n",
      "120.27116,31.483652\n",
      "距上海地铁17号线赵巷地铁站1米\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    st = 30000\n",
    "    ed = 37621\n",
    "#     37621\n",
    "#     worker_2(st,ed-st)\n",
    "    process_num = 5\n",
    "    x = math.ceil((ed-st)/process_num)\n",
    "    for i in range(0, process_num):\n",
    "        if(st+x*i > ed):\n",
    "            break\n",
    "        multiprocessing.Process(target=worker_2, args=(st+x*i, x)).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.27116,31.483652\n",
      "距上海地铁17号线赵巷地铁站698米\n"
     ]
    }
   ],
   "source": [
    "print(get_coordinate('无锡江南大学'))\n",
    "coordinate = '121.192279,31.162247'\n",
    "print(get_traffic(coordinate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补充name字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 ...\n",
      "2000 ...\n",
      "3000 ...\n",
      "4000 ...\n",
      "5000 ...\n",
      "6000 ...\n",
      "7000 ...\n",
      "8000 ...\n",
      "9000 ...\n",
      "10000 ...\n",
      "11000 ...\n",
      "12000 ...\n",
      "13000 ...\n",
      "14000 ...\n",
      "15000 ...\n",
      "16000 ...\n",
      "17000 ...\n",
      "18000 ...\n",
      "19000 ...\n",
      "20000 ...\n",
      "21000 ...\n",
      "22000 ...\n",
      "23000 ...\n",
      "24000 ...\n",
      "25000 ...\n",
      "26000 ...\n",
      "27000 ...\n",
      "28000 ...\n",
      "29000 ...\n",
      "30000 ...\n",
      "31000 ...\n",
      "32000 ...\n",
      "33000 ...\n",
      "34000 ...\n",
      "35000 ...\n",
      "36000 ...\n",
      "37000 ...\n",
      "38000 ...\n",
      "39000 ...\n",
      "40000 ...\n",
      "41000 ...\n",
      "42000 ...\n",
      "43000 ...\n",
      "44000 ...\n",
      "45000 ...\n",
      "46000 ...\n",
      "47000 ...\n",
      "48000 ...\n",
      "49000 ...\n",
      "50000 ...\n",
      "51000 ...\n",
      "52000 ...\n",
      "53000 ...\n",
      "54000 ...\n",
      "55000 ...\n",
      "56000 ...\n",
      "57000 ...\n",
      "58000 ...\n",
      "59000 ...\n",
      "60000 ...\n",
      "61000 ...\n",
      "62000 ...\n",
      "63000 ...\n",
      "64000 ...\n",
      "65000 ...\n",
      "66000 ...\n",
      "67000 ...\n",
      "68000 ...\n",
      "69000 ...\n",
      "70000 ...\n",
      "71000 ...\n",
      "72000 ...\n",
      "73000 ...\n",
      "73356 ...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import settings\n",
    "import stations_information\n",
    "import hashlib\n",
    "import logging\n",
    "import requests\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "import multiprocessing\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "MONGO_COLLECTION_1 = 'fang_details_crawl'\n",
    "MONGO_COLLECTION_2 = 'zufang58_details_crawl'\n",
    "MONGO_COLLECTION_OUTPUT = 'house_new'\n",
    "client = MongoClient(settings.MONGO_URI)\n",
    "database = client['test']\n",
    "collection_1 = database[MONGO_COLLECTION_1]\n",
    "collection_2 = database[MONGO_COLLECTION_2]\n",
    "collection_out = database[MONGO_COLLECTION_OUTPUT]\n",
    "\n",
    "st = 0\n",
    "num = 10\n",
    "\n",
    "cur = collection_out.find().skip(st)\n",
    "\n",
    "requests = []\n",
    "\n",
    "cnt = st\n",
    "\n",
    "for item in cur:\n",
    "#     print(cnt)\n",
    "#     print(item['raw_key'])\n",
    "#     print(item['url'])\n",
    "#     print(item['html'])\n",
    "    \n",
    "    if item['domain'] == 'sh.zu.fang.com':\n",
    "        item_tmp = collection_1.find({\"raw_key\":item['url']})[0]\n",
    "        soup = BeautifulSoup(item_tmp['html'], features=\"lxml\")\n",
    "        try:\n",
    "            name = soup.find(name='div', attrs={'class':\"title\"}).text.strip('\\r\\n ')\n",
    "        except Exception as e:\n",
    "            name = None\n",
    "    else:\n",
    "        item_tmp = collection_2.find({\"raw_key\":item['url']})[0]\n",
    "        soup = BeautifulSoup(item_tmp['html'], features=\"lxml\")\n",
    "        soup = BeautifulSoup(item_tmp['html'], features=\"lxml\")\n",
    "        # item_tmp['html']\n",
    "        name_str = soup.find(name='div', attrs={'class':\"house-title\"}).text.strip('\\r\\n ').split('\\n')[0]\n",
    "        script = soup.find('head').find_all('script')[0].text\n",
    "        name = ''\n",
    "        for s in name_str:\n",
    "            name += decode(script, s)\n",
    "    \n",
    "    item['name'] = name\n",
    "#     print(name)\n",
    "    \n",
    "    requests.append(UpdateOne({'raw_key': item['raw_key']}, {'$set': dict(item)}, upsert=True))\n",
    "    # 批处理\n",
    "    if(len(requests)) >= 1000:\n",
    "        collection_out.bulk_write(requests)\n",
    "        requests = []\n",
    "        cnt += 1000\n",
    "        print(cnt, '...')\n",
    "        \n",
    "collection_out.bulk_write(requests)\n",
    "cnt += len(requests)\n",
    "print(cnt, '...')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hash(data):\n",
    "    md5 = hashlib.md5() # 应用MD5算法\n",
    "    md5.update(data.encode('utf-8'))\n",
    "    return md5.hexdigest()\n",
    "\n",
    "from fontTools.ttLib import TTFont\n",
    "import base64\n",
    "import re\n",
    "import io\n",
    "\n",
    "\n",
    "def getKey(script):\n",
    "    try:\n",
    "        return re.findall(r\"base64,(.*)'\\).format\", script)[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def getFont(key):\n",
    "    data = base64.b64decode(key)\n",
    "    fonts = TTFont(io.BytesIO(data))\n",
    "    return fonts.getBestCmap()\n",
    "\n",
    "\n",
    "def getDigit(str):\n",
    "    d = re.findall(r'(\\d+)', str)[0]\n",
    "    return int(d) - 1\n",
    "\n",
    "\n",
    "def getRealValue(script, string):\n",
    "    key = getKey(script)\n",
    "#     print(key)\n",
    "    fontMap = getFont(key)\n",
    "    newMap = dict()\n",
    "    #微软雅黑的对应的编码\n",
    "    font58 = {\n",
    "        '閏': '0x958f',\n",
    "        '鸺': '0x9e3a',\n",
    "        '麣': '0x9ea3',\n",
    "        '餼': '0x993c',\n",
    "        '鑶': '0x9476',\n",
    "        '龤': '0x9fa4',\n",
    "        '齤': '0x9f64',\n",
    "        '龥': '0x9fa5',\n",
    "        '龒': '0x9f92',\n",
    "        '驋': '0x9a4b',\n",
    "    }\n",
    "    for key in fontMap.keys():\n",
    "        value = getDigit(fontMap[key])\n",
    "        key = hex(key)\n",
    "        newMap[key] = value\n",
    "    result = ''\n",
    "    for char in string:\n",
    "        temp = font58[char]\n",
    "        value = newMap[temp]\n",
    "        result = '%s%d' % (result, value)\n",
    "    return result\n",
    "\n",
    "def decode(script, price_str):\n",
    "    try:\n",
    "        res = '.'.join([getRealValue(script, it) for it in price_str.split('.')])\n",
    "    except Exception as e:\n",
    "        res = price_str\n",
    "#         print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traffic(traffic):\n",
    "#     traffic = '距离地铁5号线南延伸段金海湖站站880米'\n",
    "#     无邻近地铁则设置为3000米，因为大于2000米非地铁房\n",
    "    if not traffic:\n",
    "        return 3000\n",
    "    traffic = traffic.strip('米')\n",
    "    res = ''\n",
    "    for c in traffic[::-1]:\n",
    "        if c >= '0' and c <= '9':\n",
    "            res += c\n",
    "        else:\n",
    "            break\n",
    "    if res == '':\n",
    "        res = 3000\n",
    "    else:\n",
    "        res = int(res[::-1])\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补充subway字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 ...\n",
      "2000 ...\n",
      "3000 ...\n",
      "4000 ...\n",
      "5000 ...\n",
      "6000 ...\n",
      "7000 ...\n",
      "8000 ...\n",
      "9000 ...\n",
      "10000 ...\n",
      "11000 ...\n",
      "12000 ...\n",
      "13000 ...\n",
      "14000 ...\n",
      "15000 ...\n",
      "16000 ...\n",
      "17000 ...\n",
      "18000 ...\n",
      "19000 ...\n",
      "20000 ...\n",
      "21000 ...\n",
      "22000 ...\n",
      "23000 ...\n",
      "24000 ...\n",
      "25000 ...\n",
      "26000 ...\n",
      "27000 ...\n",
      "28000 ...\n",
      "29000 ...\n",
      "30000 ...\n",
      "31000 ...\n",
      "32000 ...\n",
      "33000 ...\n",
      "34000 ...\n",
      "35000 ...\n",
      "36000 ...\n",
      "37000 ...\n",
      "38000 ...\n",
      "39000 ...\n",
      "40000 ...\n",
      "41000 ...\n",
      "42000 ...\n",
      "43000 ...\n",
      "44000 ...\n",
      "45000 ...\n",
      "46000 ...\n",
      "47000 ...\n",
      "48000 ...\n",
      "49000 ...\n",
      "50000 ...\n",
      "51000 ...\n",
      "52000 ...\n",
      "53000 ...\n",
      "54000 ...\n",
      "55000 ...\n",
      "56000 ...\n",
      "57000 ...\n",
      "58000 ...\n",
      "59000 ...\n",
      "60000 ...\n",
      "61000 ...\n",
      "62000 ...\n",
      "63000 ...\n",
      "64000 ...\n",
      "65000 ...\n",
      "66000 ...\n",
      "67000 ...\n",
      "68000 ...\n",
      "69000 ...\n",
      "70000 ...\n",
      "71000 ...\n",
      "72000 ...\n",
      "73000 ...\n",
      "73356 ...\n"
     ]
    }
   ],
   "source": [
    "# 补充subway字段\n",
    "import re\n",
    "import math\n",
    "import settings\n",
    "import stations_information\n",
    "import hashlib\n",
    "import logging\n",
    "import requests\n",
    "from pymongo import MongoClient, UpdateOne\n",
    "\n",
    "MONGO_COLLECTION_OUTPUT = 'house_new'\n",
    "client = MongoClient(settings.MONGO_URI)\n",
    "database = client['test']\n",
    "collection_out = database[MONGO_COLLECTION_OUTPUT]\n",
    "\n",
    "st = 0\n",
    "num = 10\n",
    "cur = collection_out.find().skip(st)\n",
    "requests = []\n",
    "cnt = st\n",
    "\n",
    "for item in cur:\n",
    "#     print(item)\n",
    "    item['subway'] = get_traffic(item['traffic'])\n",
    "    requests.append(UpdateOne({'raw_key': item['raw_key']}, {'$set': dict(item)}, upsert=True))\n",
    "    # 批处理\n",
    "#     print(item)\n",
    "    if(len(requests)) >= 1000:\n",
    "        collection_out.bulk_write(requests)\n",
    "        requests = []\n",
    "        cnt += 1000\n",
    "        print(cnt, '...')\n",
    "        \n",
    "collection_out.bulk_write(requests)\n",
    "cnt += len(requests)\n",
    "print(cnt, '...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
